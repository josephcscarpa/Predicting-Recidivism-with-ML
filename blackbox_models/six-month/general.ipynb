{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Recidivism with Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.api.types import is_string_dtype, is_numeric_dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data\n",
    "\n",
    "# Whole data set for data-exploration\n",
    "whole_dataframe = pd.read_csv(\"../../data/broward_data.csv\")\n",
    "# Test train split used in XYZ paper for training our models. \n",
    "train_dataframe = pd.read_csv(\"../../data/broward_train.csv\")\n",
    "test_dataframe = pd.read_csv(\"../../data/broward_test.csv\")\n",
    "\n",
    "# whole_dataframe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Removing person_id, screening_date because they are not helpful to our analyses\n",
    "# Removing current_violence20 because redundant with 2 other columns. \n",
    "\n",
    "whole_dataframe = whole_dataframe.drop(['person_id', \"screening_date\", \"current_violence20\"], axis=1)\n",
    "test_dataframe = test_dataframe.drop(['person_id', \"screening_date\", \"current_violence20\"], axis=1)\n",
    "train_dataframe = train_dataframe.drop(['person_id', \"screening_date\", \"current_violence20\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_mapping = {\"African-American\" : 0, \"Caucasian\" : 1, \"Hispanic\" : 2, \"Other\" : 3, \"Asian\" : 4, \"Native American\" : 5, }\n",
    "whole_dataframe['race'] = whole_dataframe['race'].map(race_mapping)\n",
    "train_dataframe['race'] = train_dataframe['race'].map(race_mapping)\n",
    "test_dataframe['race'] = test_dataframe['race'].map(race_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_column_names = ['six_month', 'one_year', 'three_year', 'five_year', 'general_two_year',\n",
    "       'general_six_month', 'drug_two_year', 'property_two_year',\n",
    "       'misdemeanor_two_year', 'felony_two_year', 'violent_two_year',\n",
    "       'drug_six_month', 'property_six_month', 'misdemeanor_six_month',\n",
    "       'felony_six_month', 'violent_six_month']\n",
    "\n",
    "whole_dataframe_X = whole_dataframe.drop(label_column_names, axis = 1)\n",
    "whole_dataframe_label_choices = whole_dataframe[label_column_names]\n",
    "whole_data_X = whole_dataframe_X.values\n",
    "# To get numpy y-labels: append {.astype(int).values} to end of label series\n",
    "\n",
    "test_dataframe_X = test_dataframe.drop(label_column_names, axis = 1)\n",
    "test_dataframe_label_choices = test_dataframe[label_column_names]\n",
    "test_data_X = test_dataframe_X.values\n",
    "test_data_y = test_dataframe_label_choices[\"general_six_month\"].astype(int).values\n",
    "\n",
    "train_dataframe_X = train_dataframe.drop(label_column_names, axis = 1)\n",
    "train_dataframe_label_choices = train_dataframe[label_column_names]\n",
    "train_data_X = train_dataframe_X.values\n",
    "train_data_y = train_dataframe_label_choices[\"general_six_month\"].astype(int).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data_X\n",
    "y_train = train_data_y\n",
    "X_test = test_data_X\n",
    "y_test = test_data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_num = 816"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(816)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics Import\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics: AUC\n",
    "Additionally, our evaluation metric is AUC, which is a rank statistic, and considers relative risk rather than absolute risk;\n",
    "\n",
    "https://datascience.stackexchange.com/questions/30881/when-is-precision-more-important-over-recall#:~:text=Thus%2C%20precision%20will%20be%20more,having%20any%20action%20at%20all%22.\n",
    "\n",
    "Metric: Precision\n",
    "Picked this metric on the assumption that a false negative (predicting a person will not be charged when they will be) is better than false positives.\n",
    "\n",
    "Metric: F1-Score:\n",
    "A good metric because our dataset is imbalanced and combines the power of precision and recall. \n",
    "\n",
    "Metric: Log-Loss:\n",
    "Useful for assessing the uncertainty of our predictions, which is useful, considering the decisions of our decisions affect real people. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Creation and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "lreg_grid = {\n",
    "    'penalty': ['l2'],\n",
    "    'solver' : ['liblinear'],\n",
    "    'C':[10**-5, 10**-4, 10**-3, 10**-2],\n",
    "    'class_weight': ['balanced'],\n",
    "    'max_iter': [10000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "lreg_cv = GridSearchCV(estimator = LogisticRegression(random_state=state_num), \n",
    "                                    param_grid = lreg_grid, \n",
    "                                    cv = 5\n",
    "                                    )\n",
    "lreg_cv.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1e-05, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "print(lreg_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1e-05, class_weight='balanced', max_iter=10000,\n",
       "                   random_state=816, solver='liblinear')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lreg_clf = LogisticRegression(\n",
    "    penalty = 'l2',\n",
    "    solver = 'liblinear',\n",
    "    C = lreg_cv.best_params_.get('C'),\n",
    "    class_weight='balanced', \n",
    "    max_iter=10000, \n",
    "    random_state=state_num\n",
    "    )\n",
    "lreg_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC of Logistic Regression for Best Model\n",
      "0.6200964320154292\n"
     ]
    }
   ],
   "source": [
    "# Print AUC \n",
    "print(\"AUC of Logistic Regression for Best Model\")\n",
    "print(roc_auc_score(y_test, lreg_clf.decision_function(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross Fold Validation for Random Forest\n",
    "\n",
    "rf_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [1, 2, 3],\n",
    "    'min_impurity_decrease': [.001, .002, .003, .004, .005, .006, .007, .008, .009, .010] \n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 1, 'min_impurity_decrease': 0.001, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "rf_cv = GridSearchCV(estimator = RandomForestClassifier(random_state=state_num), \n",
    "                                    param_grid = rf_grid, \n",
    "                                    cv = 5\n",
    "                                    )\n",
    "rf_cv.fit(X_train, y_train)\n",
    "print(rf_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=1, min_impurity_decrease=0.001,\n",
       "                       n_estimators=50, random_state=816)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(\n",
    "    n_estimators = rf_cv.best_params_.get('n_estimators'), \n",
    "    max_depth = rf_cv.best_params_.get('max_depth'), \n",
    "    min_impurity_decrease = rf_cv.best_params_.get('min_impurity_decrease'), \n",
    "    random_state=state_num\n",
    "    )\n",
    "rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC of Logistic Regression for Best Model\n",
      "0.6128833172613308\n"
     ]
    }
   ],
   "source": [
    "# Print AUC \n",
    "print(\"AUC of Logistic Regression for Best Model\")\n",
    "print(roc_auc_score(y_test, rf_clf.predict_proba(X_test)[:,1]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross Fold Validation for Random Forest\n",
    "\n",
    "svm_grid = {\n",
    "    'C':[10**-5, 10**-4, 10**-3, 10**-2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "svm_cv = GridSearchCV(estimator = LinearSVC(random_state=state_num), \n",
    "                                    param_grid = svm_grid, \n",
    "                                    cv = 5\n",
    "                                    )\n",
    "svm_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1e-05, random_state=816)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf = LinearSVC(\n",
    "    C = svm_cv.best_params_.get('C'), \n",
    "    random_state=state_num\n",
    "    )\n",
    "svm_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC of Logistic Regression for Best Model\n",
      "0.6006943105110896\n"
     ]
    }
   ],
   "source": [
    "# Print AUC \n",
    "print(\"AUC of Logistic Regression for Best Model\")\n",
    "print(roc_auc_score(y_test, svm_clf.decision_function(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boosted Decision Trees (ADA Boost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_grid = { \n",
    "    'learning_rate': [0.05],\n",
    "    'n_estimators': [50, 100, 200]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.05, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "ada_cv = GridSearchCV(\n",
    "    estimator = AdaBoostClassifier(random_state=state_num),\n",
    "    param_grid = ada_grid,\n",
    "    cv = 5\n",
    ")\n",
    "ada_cv.fit(X_train, y_train)\n",
    "print(ada_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(learning_rate=0.05, random_state=816)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_clf= AdaBoostClassifier(\n",
    "    n_estimators = ada_cv.best_params_.get('n_estimators'), \n",
    "    learning_rate = ada_cv.best_params_.get('learning_rate'), \n",
    "    random_state=state_num\n",
    "    )\n",
    "ada_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC of Logistic Regression for Best Model\n",
      "0.6275988428158148\n"
     ]
    }
   ],
   "source": [
    "# Print AUC \n",
    "print(\"AUC of Logistic Regression for Best Model\")\n",
    "print(roc_auc_score(y_test, ada_clf.predict_proba(X_test)[:,1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "a25f99aa125bd4410be9155a2fb8511cd1ed013e1077370425d4be963778dfe3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

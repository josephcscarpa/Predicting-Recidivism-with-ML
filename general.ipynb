{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Recidivism with Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.api.types import is_string_dtype, is_numeric_dtype\n",
    "\n",
    "import time\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data\n",
    "\n",
    "# Whole data set for data-exploration\n",
    "whole_dataframe = pd.read_csv(\"data/broward_data.csv\")\n",
    "# Test train split used in XYZ paper for training our models. \n",
    "train_dataframe = pd.read_csv(\"data/broward_train.csv\")\n",
    "test_dataframe = pd.read_csv(\"data/broward_test.csv\")\n",
    "\n",
    "# whole_dataframe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Removing person_id, screening_date because they are not helpful to our analyses\n",
    "# Removing current_violence20 because redundant with 2 other columns. \n",
    "\n",
    "whole_dataframe = whole_dataframe.drop(['person_id', \"screening_date\", \"current_violence20\"], axis=1)\n",
    "test_dataframe = test_dataframe.drop(['person_id', \"screening_date\", \"current_violence20\"], axis=1)\n",
    "train_dataframe = train_dataframe.drop(['person_id', \"screening_date\", \"current_violence20\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_mapping = {\"African-American\" : 0, \"Caucasian\" : 1, \"Hispanic\" : 2, \"Other\" : 3, \"Asian\" : 4, \"Native American\" : 5, }\n",
    "whole_dataframe['race'] = whole_dataframe['race'].map(race_mapping)\n",
    "train_dataframe['race'] = train_dataframe['race'].map(race_mapping)\n",
    "test_dataframe['race'] = test_dataframe['race'].map(race_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_column_names = ['six_month', 'one_year', 'three_year', 'five_year', 'general_two_year',\n",
    "       'general_six_month', 'drug_two_year', 'property_two_year',\n",
    "       'misdemeanor_two_year', 'felony_two_year', 'violent_two_year',\n",
    "       'drug_six_month', 'property_six_month', 'misdemeanor_six_month',\n",
    "       'felony_six_month', 'violent_six_month']\n",
    "\n",
    "whole_dataframe_X = whole_dataframe.drop(label_column_names, axis = 1)\n",
    "whole_dataframe_label_choices = whole_dataframe[label_column_names]\n",
    "whole_data_X = whole_dataframe_X.values\n",
    "# To get numpy y-labels: append {.astype(int).values} to end of label series\n",
    "\n",
    "# TEST Dataframe with only X \n",
    "test_dataframe_X = test_dataframe.drop(label_column_names, axis = 1)\n",
    "# np-array from dataframe\n",
    "test_data_X = test_dataframe_X.values\n",
    "# Generate labels as np-array\n",
    "test_dataframe_label_choices = test_dataframe[label_column_names]\n",
    "test_data_y = test_dataframe_label_choices[\"general_six_month\"].astype(int).values\n",
    "\n",
    "# TRAIN Dataframe with only X\n",
    "train_dataframe_X = train_dataframe.drop(label_column_names, axis = 1)\n",
    "# np-array from dataframe\n",
    "train_data_X = train_dataframe_X.values\n",
    "# Generate labels as np-array\n",
    "train_dataframe_label_choices = train_dataframe[label_column_names]\n",
    "train_data_y = train_dataframe_label_choices[\"general_six_month\"].astype(int).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_num = 816\n",
    "np.random.seed(816)\n",
    "\n",
    "# Models Import\n",
    "\n",
    "import sklearn\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from gosdt_model.threshold_guess import compute_thresholds\n",
    "from gosdt import GOSDT\n",
    "\n",
    "# Metrics Import\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBDT parameters for threshold and lower bound guesses\n",
    "n_est = 40\n",
    "max_depth = 1\n",
    "\n",
    "# guess thresholds\n",
    "X_train, thresholds, header, threshold_guess_time = compute_thresholds(train_dataframe_X, y_train, n_est, max_depth)\n",
    "y_train = pd.DataFrame(train_data_y)\n",
    "\n",
    "# guess lower bound\n",
    "start_time = time.perf_counter()\n",
    "clf = GradientBoostingClassifier(n_estimators=n_est, max_depth=max_depth)\n",
    "clf.fit(X_train, y_train.values.flatten())\n",
    "warm_labels = clf.predict(X_train)\n",
    "elapsed_time = time.perf_counter() - start_time\n",
    "lb_time = elapsed_time\n",
    "\n",
    "# save the labels from lower bound guesses as a tmp file and return the path to it.\n",
    "labelsdir = pathlib.Path('/tmp/warm_lb_labels')\n",
    "labelsdir.mkdir(exist_ok=True, parents=True)\n",
    "labelpath = labelsdir / 'warm_label.tmp'\n",
    "labelpath = str(labelpath)\n",
    "pd.DataFrame(warm_labels, columns=[\"class_labels\"]).to_csv(labelpath, header=\"class_labels\",index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.003 (user, system, wall), mem=0 MB\n",
      "bounds: [0.217473..0.217473] (0.000000) loss=0.215473, iterations=0\n",
      "evaluate the model, extracting tree and scores\n",
      "Model training time: 0.0\n",
      "Training accuracy: 0.7845268542199488\n",
      "# of leaves: 2\n",
      "if p_drug<=26.0 = 1 then:\n",
      "    predicted class: 0\n",
      "    misclassification penalty: 0.215\n",
      "    complexity penalty: 0.001\n",
      "\n",
      "else if p_drug<=26.0 != 1 then:\n",
      "    predicted class: 1\n",
      "    misclassification penalty: 0.0\n",
      "    complexity penalty: 0.001\n"
     ]
    }
   ],
   "source": [
    "# train GOSDT model\n",
    "config = {\n",
    "            \"regularization\": 0.001,\n",
    "            \"depth_budget\": 5,\n",
    "            \"warm_LB\": True,\n",
    "            \"path_to_labels\": labelpath,\n",
    "            \"time_limit\": 60,\n",
    "            \"similar_support\": False\n",
    "        }\n",
    "\n",
    "model = GOSDT(config)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"evaluate the model, extracting tree and scores\", flush=True)\n",
    "\n",
    "# get the results\n",
    "train_acc = model.score(X_train, y_train)\n",
    "n_leaves = model.leaves()\n",
    "n_nodes = model.nodes()\n",
    "time = model.utime\n",
    "\n",
    "print(\"Model training time: {}\".format(time))\n",
    "print(\"Training accuracy: {}\".format(train_acc))\n",
    "print(\"# of leaves: {}\".format(n_leaves))\n",
    "print(model.tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC of Logistic Regression for Best Model\n",
      "0.6128833172613308\n"
     ]
    }
   ],
   "source": [
    "# Print AUC \n",
    "print(\"AUC of Logistic Regression for Best Model\")\n",
    "print(roc_auc_score(y_test, rf_clf.predict_proba(X_test)[:,1]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "a25f99aa125bd4410be9155a2fb8511cd1ed013e1077370425d4be963778dfe3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

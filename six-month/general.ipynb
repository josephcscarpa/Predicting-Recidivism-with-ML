{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Recidivism with Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.api.types import is_string_dtype, is_numeric_dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Import data\"\n",
    "# Whole data set for data-exploration\n",
    "whole_dataframe = pd.read_csv(\"../data/broward_data.csv\")\n",
    "# Test train split used in XYZ paper for training our models. \n",
    "train_dataframe = pd.read_csv(\"../data/broward_train.csv\")\n",
    "test_dataframe = pd.read_csv(\"../data/broward_test.csv\")\n",
    "\n",
    "# whole_dataframe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Removing person_id, screening_date because they are not helpful to our analyses\n",
    "Removing current_violence20 because redundant with 2 other columns. \n",
    "\"\"\"\n",
    "whole_dataframe = whole_dataframe.drop(['person_id', \"screening_date\", \"current_violence20\"], axis=1)\n",
    "test_dataframe = test_dataframe.drop(['person_id', \"screening_date\", \"current_violence20\"], axis=1)\n",
    "train_dataframe = train_dataframe.drop(['person_id', \"screening_date\", \"current_violence20\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_mapping = {\"African-American\" : 0, \"Caucasian\" : 1, \"Hispanic\" : 2, \"Other\" : 3, \"Asian\" : 4, \"Native American\" : 5, }\n",
    "whole_dataframe['race'] = whole_dataframe['race'].map(race_mapping)\n",
    "train_dataframe['race'] = train_dataframe['race'].map(race_mapping)\n",
    "test_dataframe['race'] = test_dataframe['race'].map(race_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_column_names = ['six_month', 'one_year', 'three_year', 'five_year', 'general_two_year',\n",
    "       'general_six_month', 'drug_two_year', 'property_two_year',\n",
    "       'misdemeanor_two_year', 'felony_two_year', 'violent_two_year',\n",
    "       'drug_six_month', 'property_six_month', 'misdemeanor_six_month',\n",
    "       'felony_six_month', 'violent_six_month']\n",
    "\n",
    "whole_dataframe_X = whole_dataframe.drop(label_column_names, axis = 1)\n",
    "whole_dataframe_label_choices = whole_dataframe[label_column_names]\n",
    "whole_data_X = whole_dataframe_X.values\n",
    "\"To get numpy y-labels: append {.astype(int).values} to end of label series\"\n",
    "\n",
    "test_dataframe_X = test_dataframe.drop(label_column_names, axis = 1)\n",
    "test_dataframe_label_choices = test_dataframe[label_column_names]\n",
    "test_data_X = test_dataframe_X.values\n",
    "test_data_y = test_dataframe_label_choices[\"general_six_month\"].astype(int).values\n",
    "\n",
    "train_dataframe_X = train_dataframe.drop(label_column_names, axis = 1)\n",
    "train_dataframe_label_choices = train_dataframe[label_column_names]\n",
    "train_data_X = train_dataframe_X.values\n",
    "train_data_y = train_dataframe_label_choices[\"general_six_month\"].astype(int).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data_X\n",
    "y_train = train_data_y\n",
    "X_test = test_data_X\n",
    "y_test = test_data_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(671)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics: AUC\n",
    "Additionally, our evaluation metric is AUC, which is a rank statistic, and considers relative risk rather than absolute risk;\n",
    "\n",
    "https://datascience.stackexchange.com/questions/30881/when-is-precision-more-important-over-recall#:~:text=Thus%2C%20precision%20will%20be%20more,having%20any%20action%20at%20all%22.\n",
    "\n",
    "Metric: Precision\n",
    "Picked this metric on the assumption that a false negative (predicting a person will not be charged when they will be) is better than false positives.\n",
    "\n",
    "Metric: F1-Score:\n",
    "A good metric because our dataset is imbalanced and combines the power of precision and recall. \n",
    "\n",
    "Metric: Log-Loss:\n",
    "Useful for assessing the uncertainty of our predictions, which is useful, considering the decisions of our decisions affect real people. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lreg_grid = {\n",
    "    'penalty': ['none', 'l1', 'l2', 'elasticnet'],\n",
    "    'fit_intercept': [True, False],\n",
    "    'C':[10**-5, 10**-4, 10**-3, 10**-2, 10**-1, 10**0, 10**2],\n",
    "    'tol': [.00001, .0001, .001, .01, .1, 1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lreg_cv = GridSearchCV(estimator = LogisticRegression(), \n",
    "                                    param_grid = lreg_grid, \n",
    "                                    cv = 5\n",
    "                                    )\n",
    "lreg_cv.fit(X_train, y_train)\n",
    "print(lreg_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lreg_clf = LogisticRegression(\n",
    "    penalty = lreg_cv.best_params_.get('penalty'), \n",
    "    fit_intercept = lreg_cv.best_params_.get('fit_intercept'), \n",
    "    C = lreg_cv.best_params_.get('C'),\n",
    "    tol = lasso_cv.best_params_.get('tol')\n",
    "    )\n",
    "lreg_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_grid = {\n",
    "    'alpha': [2, 4, 8, 16, 32, 64, 128],\n",
    "    'fit_intercept': [True, False],\n",
    "    'tol': [.00001, .0001, .001, .01, .1, 1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_cv = GridSearchCV(estimator = Lasso(), \n",
    "                                    param_grid = lasso_grid, \n",
    "                                    cv = 5\n",
    "                                    )\n",
    "lasso_cv.fit(X_train, y_train)\n",
    "print(lasso_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_clf = Lasso(\n",
    "    alpha = lasso_cv.best_params_.get('alpha'), \n",
    "    fit_intercept = lasso_cv.best_params_.get('fit_intercept'), \n",
    "    tol = lasso_cv.best_params_.get('tol'), \n",
    "    )\n",
    "lasso_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross Fold Validation for Random Forest\n",
    "\n",
    "rf_grid = {\n",
    "    'n_estimators': [2, 4, 8, 16, 32, 64, 128],\n",
    "    'max_features': [1, 2, 3, 4, 5, 6],\n",
    "    'max_depth': list(range(1, 32+1)),\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'], \n",
    "    'random_state' : [0]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cv = GridSearchCV(estimator = RandomForestClassifier(), \n",
    "                                    param_grid = rf_grid, \n",
    "                                    cv = 5\n",
    "                                    )\n",
    "rf_cv.fit(X_train, y_train)\n",
    "print(rf_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(\n",
    "    n_estimators = rf_cv.best_params_.get('n_estimators'), \n",
    "    max_depth = rf_cv.best_params_.get('max_depth'), \n",
    "    max_features = rf_cv.best_params_.get('max_features'), \n",
    "    criterion = rf_cv.best_params_.get('criterion')\n",
    "    )\n",
    "rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boosted Decision Trees (ADA Boost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_grid = {\n",
    "    'n_estimators': [2, 4, 8, 16, 32, 64, 128],\n",
    "    'learning_rate': [0.1, 0.25, 0.5, 0.75, 0.9, 1.0, 1.25, 1.5, 2],\n",
    "    'algorithm': ['SAMME', 'SAMME.R'],\n",
    "    'random_state' : [0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_cv = GridSearchCV(\n",
    "    estimator = AdaBoostClassifier(),\n",
    "    param_grid = ada_grid,\n",
    "    cv = 5\n",
    ")\n",
    "ada_cv.fit(X_train, y_train)\n",
    "print(ada_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_clf= AdaBoostClassifier(\n",
    "    n_estimators = ada_cv.best_params_.get('n_estimators'), \n",
    "    learning_rate = ada_cv.best_params_.get('learning_rate'), \n",
    "    algorithm = ada_cv.best_params_.get('algorithm')\n",
    "    )\n",
    "ada_clf.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "a25f99aa125bd4410be9155a2fb8511cd1ed013e1077370425d4be963778dfe3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
